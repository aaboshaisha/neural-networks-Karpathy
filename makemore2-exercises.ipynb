{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28202c3-daf3-4e84-bcf5-b95d0423c299",
   "metadata": {},
   "source": [
    "### Exercises: Building makemore Part 2: MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bc8bf-d8f8-44cf-8a2f-4b7e7b0fd830",
   "metadata": {},
   "source": [
    "- E01: Tune the hyperparameters of the training to beat my best validation loss of 2.2\n",
    "- E02: I was not careful with the intialization of the network in this video. (1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? (2) Can you tune the initialization to get a starting loss that is much more similar to (1)?\n",
    "- E03: Read the Bengio et al 2003 paper (link above), implement and try any idea from the paper. Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "714f3516-20d8-4313-932f-ad365e442a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21d44d-e0a1-4d5b-8189-0b36a7594722",
   "metadata": {},
   "source": [
    "### E01: \n",
    "Tune the hyperparameters of the training to beat my best validation loss of 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "535041e0-7032-4f63-953b-d7a75b631216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4643cff4-b36e-412c-831a-2553af8d29ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "908d6bfc-3baf-41da-abb1-7b74110a481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "1017754c-5b4d-4bbb-84ee-856953846c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create datasets\n",
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for word in words:\n",
    "        context = [0] * block_size\n",
    "        \n",
    "        for ch in word+'.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af559945-508c-49b9-9430-305456430031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "accfac2e-783a-486c-aabc-05555fa97167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train / dev / test 80/10/10\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words)) # index for 80 - 90 \n",
    "n2 = int(0.9*len(words)) # index for 90 - 100\n",
    "\n",
    "xtr, ytr = build_dataset(words[:n1])\n",
    "xdev, ydev = build_dataset(words[n1:n2])\n",
    "xte, yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ca3a279-092f-44e3-9c7e-c55b48066920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182580, 3]),\n",
       " torch.Size([182580]),\n",
       " torch.Size([22767, 3]),\n",
       " torch.Size([22767]),\n",
       " torch.Size([22799, 3]),\n",
       " torch.Size([22799]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr.shape, ytr.shape, xdev.shape, ydev.shape, xte.shape, yte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5679808f-735e-447a-ba37-0f5c328a3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize embedding layer, weights and biases\n",
    "feature_size = 10 #size of feature vector\n",
    "C = torch.randn((27, feature_size))\n",
    "emb = C[xtr].view(-1, block_size * feature_size)\n",
    "hidden_size = 200\n",
    "W1 = torch.randn((block_size * feature_size, hidden_size), requires_grad = True)\n",
    "b1 = torch.randn(hidden_size, requires_grad = True)\n",
    "W2 = torch.randn((hidden_size, 27), requires_grad = True)\n",
    "b2 = torch.randn(27, requires_grad = True)\n",
    "\n",
    "parameters = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0f923351-e061-41d7-93dc-a67ed4357bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, num_iters, lr, bs):\n",
    "    # keep stats\n",
    "    lossi = []\n",
    "    iteration = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        ixs = torch.randint(0, X.shape[0], (bs, ))\n",
    "        # forward\n",
    "        hidden = torch.tanh((C[X[ixs]].view(-1, block_size * feature_size) @ W1 + b1))\n",
    "        logits = hidden @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Y[ixs])\n",
    "    \n",
    "        # backward\n",
    "        for p in parameters: # zero grads\n",
    "            p.grad = None\n",
    "        loss.backward() #backprop\n",
    "\n",
    "        #lr = 0.1 if i < 10000 else lr\n",
    "        if i < 100000:\n",
    "            lr = 0.1\n",
    "        elif ((i > 100000) and (i < 150000)):\n",
    "            lr = 0.01\n",
    "        else:\n",
    "            lr = lr\n",
    "        \n",
    "        for p in parameters: # weight update\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        iteration.append(i)\n",
    "    \n",
    "    return iteration, lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "805a4e88-76a1-450b-a694-15ca01786c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(x, y):\n",
    "    hidden = torch.tanh(C[x].view(-1, block_size * feature_size) @ W1 + b1)\n",
    "    logits = hidden @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y).item()\n",
    "    print(f'Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0f5c884e-1a83-4748-b676-0b8d535a16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, lossi = train(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ab4edf63-e933-4432-87f9-dc3f3acaf150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.190006732940674"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossi[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c643365e-98c5-406b-aca8-47e702d1ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0791778564453125\n"
     ]
    }
   ],
   "source": [
    "eval_loss(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "44b95d9e-264f-4f36-b3eb-0c6bdf309bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1441211700439453\n"
     ]
    }
   ],
   "source": [
    "eval_loss(xdev, ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd5924-b824-4220-b5bb-3e6ba36ff8a7",
   "metadata": {},
   "source": [
    "Managed to beat Karpathy's score. I doubled the batch size to 64, iterated for 200,000 times and varied the learning rate during the iterations such that the network uses a slower learning rate the more iterations it goes through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5806f5-4f1a-4bbf-a018-3766cee34fe1",
   "metadata": {},
   "source": [
    "### E02: \n",
    "I was not careful with the intialization of the network in this video. \n",
    "\n",
    "(1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve?\\\n",
    "(2) Can you tune the initialization to get a starting loss that is much more similar to (1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f097b5e-1303-481a-9d12-d0227755dd57",
   "metadata": {},
   "source": [
    "#### E2-1 What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3d425da7-452e-42be-8d3b-0accd13f7268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3361799716949463"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_logits = torch.nn.init.uniform_(logits, 0, 1)\n",
    "uniform_loss = F.cross_entropy(uniform_logits, ytr)\n",
    "uniform_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb85f84-6431-4fb4-a79b-e915ee710d1d",
   "metadata": {},
   "source": [
    "#### E2-2 Can you tune the initialization to get a starting loss that is much more similar to (1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "069b0471-42ff-4dbb-933a-b6939da72b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200\n",
    "W1 = torch.ones((block_size * feature_size, hidden_size))\n",
    "b1 = torch.ones(hidden_size)\n",
    "W2 = torch.ones((hidden_size, 27))\n",
    "b2 = torch.ones(27)\n",
    "\n",
    "parameters = [W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "88e89a5f-2cba-4a87-8fe3-2d0e5a9e51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.295837163925171\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "hidden = torch.tanh((C[xtr].view(-1, block_size * feature_size) @ W1 + b1))\n",
    "logits = hidden @ W2 + b2\n",
    "loss = F.cross_entropy(logits, ytr)\n",
    "\n",
    "# backward\n",
    "for p in parameters: # zero grads\n",
    "    p.grad = None\n",
    "loss.backward() #backprop\n",
    "\n",
    "for p in parameters: # weight update\n",
    "    p.data -= 0.5 * p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451425c-3197-4dc6-9311-53d7203dd130",
   "metadata": {},
   "source": [
    "We want the predicted probabilities to be perfectly uniform.\\\n",
    "Remeber how we get `F.cross_entropy(logits, ytr)`:\n",
    "\n",
    "```\n",
    "logits = ....\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "```\n",
    "So, probs will be uniform if counts were the same which means logits are the same.\\\n",
    "logits are the same if we set all the weights and biases of the network to be the same = 1 (which means our network expects all embeddings to be equally likely)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2d35a-82fc-4fa9-9c11-fbf141300ade",
   "metadata": {},
   "source": [
    "#### E03 \n",
    "Read the Bengio et al 2003 paper (link above), implement and try any idea from the paper. Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4f426767-b81b-4bc5-869a-9a6c8cb54ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll experiment with regularization\n",
    "# initialize embedding layer, weights and biases\n",
    "feature_size = 10 #size of feature vector\n",
    "C = torch.randn((27, feature_size))\n",
    "emb = C[xtr].view(-1, block_size * feature_size)\n",
    "hidden_size = 200\n",
    "W1 = torch.randn((block_size * feature_size, hidden_size), requires_grad = True)\n",
    "b1 = torch.randn(hidden_size, requires_grad = True)\n",
    "W2 = torch.randn((hidden_size, 27), requires_grad = True)\n",
    "b2 = torch.randn(27, requires_grad = True)\n",
    "\n",
    "parameters = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "220713a7-12e8-4196-96b6-1b63e5da0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(X, Y, num_iters, lr, bs):\n",
    "    # keep stats\n",
    "    lossi = []\n",
    "    iteration = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        ixs = torch.randint(0, X.shape[0], (bs, ))\n",
    "        # forward\n",
    "        hidden = torch.tanh((C[X[ixs]].view(-1, block_size * feature_size) @ W1 + b1))\n",
    "        logits = hidden @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Y[ixs]) + W1.pow(2).mean() + W2.pow(2).mean()\n",
    "    \n",
    "        # backward\n",
    "        for p in parameters: # zero grads\n",
    "            p.grad = None\n",
    "        loss.backward() #backprop\n",
    "\n",
    "        #lr = 0.1 if i < 10000 else lr\n",
    "        if i < 100000:\n",
    "            lr = 0.1\n",
    "        elif ((i > 100000) and (i < 150000)):\n",
    "            lr = 0.01\n",
    "        else:\n",
    "            lr = lr\n",
    "        \n",
    "        for p in parameters: # weight update\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        iteration.append(i)\n",
    "    \n",
    "    return iteration, lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0dd96954-1690-4b31-a55d-6b7304ddcb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss2(x, y):\n",
    "    hidden = torch.tanh(C[x].view(-1, block_size * feature_size) @ W1 + b1)\n",
    "    logits = hidden @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y).item() + W1.pow(2).mean() + W2.pow(2).mean()\n",
    "    print(f'Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8e710a8c-fe31-4cc2-a208-21939c92839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2, losses2 = train2(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ce43e1cc-e643-4e40-af80-437ceb9c6db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.208491086959839\n",
      "Loss: 2.237893581390381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss2(xtr, ytr), eval_loss2(xdev, ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f33e48ca-1330-4515-a226-f86c513ffaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try it with the uniformly initialized weights\n",
    "hidden_size = 200\n",
    "W1 = torch.ones((block_size * feature_size, hidden_size))\n",
    "b1 = torch.ones(hidden_size)\n",
    "W2 = torch.ones((hidden_size, 27))\n",
    "b2 = torch.ones(27)\n",
    "\n",
    "parameters = [W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9f1c8005-e0bf-4ad4-96d2-80cf91c6cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2, losses2 = train2(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "89f45bcb-2a04-48a6-a9f2-cc5f2b84c6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.534567356109619\n",
      "Loss: 2.5287091732025146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss2(xtr, ytr), eval_loss2(xdev, ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ab3836f7-1656-4ac2-a1a7-bb384febf941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(i2, losses2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa120c-4b67-4d7e-aa7d-494d16c9975f",
   "metadata": {},
   "source": [
    "I ran a couple of experiments with regularization using different batch sizes (32 and 64), also using randomly vs uniformly initialized weights. In both cases we couldn't improve on the previous result and we had worse loss with the uniform initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbea22-ec46-42d9-9a86-0db5f792e29d",
   "metadata": {},
   "source": [
    "**NB** I found out I trained all the above without inclduing C in the list of parameters to be backpropagated on. I'll repeat some of the experiments again while including C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "31069499-274a-436e-951f-c4661e3d94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 10 #size of feature vector\n",
    "C = torch.randn((27, feature_size), requires_grad = True)\n",
    "emb = C[xtr].view(-1, block_size * feature_size)\n",
    "hidden_size = 200\n",
    "W1 = torch.randn((block_size * feature_size, hidden_size), requires_grad = True)\n",
    "b1 = torch.randn(hidden_size, requires_grad = True)\n",
    "W2 = torch.randn((hidden_size, 27), requires_grad = True)\n",
    "b2 = torch.randn(27, requires_grad = True)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "81f9d9ae-a6bf-4d30-81fa-1a8be8db9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, num_iters, lr, bs):\n",
    "    # keep stats\n",
    "    lossi = []\n",
    "    iteration = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        ixs = torch.randint(0, X.shape[0], (bs, ))\n",
    "        # forward\n",
    "        hidden = torch.tanh((C[X[ixs]].view(-1, block_size * feature_size) @ W1 + b1))\n",
    "        logits = hidden @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Y[ixs])\n",
    "    \n",
    "        # backward\n",
    "        for p in parameters: # zero grads\n",
    "            p.grad = None\n",
    "        loss.backward() #backprop\n",
    "\n",
    "        #lr = 0.1 if i < 10000 else lr\n",
    "        if i < 100000:\n",
    "            lr = 0.1\n",
    "        elif ((i > 100000) and (i < 150000)):\n",
    "            lr = 0.01\n",
    "        else:\n",
    "            lr = lr\n",
    "        \n",
    "        for p in parameters: # weight update\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        iteration.append(i)\n",
    "    \n",
    "    return iteration, lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "61632229-69af-46d0-af59-a866cd783788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(x, y):\n",
    "    hidden = torch.tanh(C[x].view(-1, block_size * feature_size) @ W1 + b1)\n",
    "    logits = hidden @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y).item()\n",
    "    print(f'Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "40dcf83e-eed6-4070-ace5-beffb5cb0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, lossi = train(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "2c420189-5fbd-4eb6-8f73-fb0289ea9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1048717498779297\n",
      "Loss: 2.149653911590576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss(xtr, ytr), eval_loss(xdev, ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7524409-6708-4ce6-8354-2d8e4c4beeac",
   "metadata": {},
   "source": [
    "Ok, we get the same losses as before (without C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00167226-7c14-47d8-8f68-a95bd4584707",
   "metadata": {},
   "source": [
    "#### Use uniform weight initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "08a3f6e9-47ee-4a04-a24e-9c556fe5615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 10 #size of feature vector\n",
    "C = torch.ones((27, feature_size), requires_grad = True)\n",
    "emb = C[xtr].view(-1, block_size * feature_size)\n",
    "hidden_size = 200\n",
    "W1 = torch.ones((block_size * feature_size, hidden_size), requires_grad = True)\n",
    "b1 = torch.ones(hidden_size, requires_grad = True)\n",
    "W2 = torch.ones((hidden_size, 27), requires_grad = True)\n",
    "b2 = torch.ones(27, requires_grad = True)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f903f0df-b589-4150-ab78-06a7b2e3fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, lossi = train(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ee00414c-b692-4b83-807e-79fff2945da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.8340959548950195\n",
      "Loss: 2.827920913696289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss(xtr, ytr), eval_loss(xdev, ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cad15-d178-4b1a-a019-ae0300bde278",
   "metadata": {},
   "source": [
    "Much worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf4083-9876-4849-bdbc-1898c3543980",
   "metadata": {},
   "source": [
    "#### Use Regularization in loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "138ebd77-7356-45b1-8af0-c88c4062adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 10 #size of feature vector\n",
    "C = torch.randn((27, feature_size), requires_grad = True)\n",
    "emb = C[xtr].view(-1, block_size * feature_size)\n",
    "hidden_size = 200\n",
    "W1 = torch.randn((block_size * feature_size, hidden_size), requires_grad = True)\n",
    "b1 = torch.randn(hidden_size, requires_grad = True)\n",
    "W2 = torch.randn((hidden_size, 27), requires_grad = True)\n",
    "b2 = torch.randn(27, requires_grad = True)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "041edaea-845f-41fb-be8d-8e9df83542a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, num_iters, lr, bs):\n",
    "    # keep stats\n",
    "    lossi = []\n",
    "    iteration = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        ixs = torch.randint(0, X.shape[0], (bs, ))\n",
    "        # forward\n",
    "        hidden = torch.tanh((C[X[ixs]].view(-1, block_size * feature_size) @ W1 + b1))\n",
    "        logits = hidden @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Y[ixs]) + W1.pow(2).mean() + W2.pow(2).mean()\n",
    "    \n",
    "        # backward\n",
    "        for p in parameters: # zero grads\n",
    "            p.grad = None\n",
    "        loss.backward() #backprop\n",
    "\n",
    "        #lr = 0.1 if i < 10000 else lr\n",
    "        if i < 100000:\n",
    "            lr = 0.1\n",
    "        elif ((i > 100000) and (i < 150000)):\n",
    "            lr = 0.01\n",
    "        else:\n",
    "            lr = lr\n",
    "        \n",
    "        for p in parameters: # weight update\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        iteration.append(i)\n",
    "    \n",
    "    return iteration, lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5882e9b8-63cf-4e31-91b2-af1cfec076cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, lossi = train(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0d3435d5-7c6d-433e-a76d-f3db1b141e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.059695243835449\n",
      "Loss: 2.106905698776245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss(xtr, ytr), eval_loss(xdev, ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57039f-705d-4656-80b2-f974dc8a972f",
   "metadata": {},
   "source": [
    "Not bad. Slight improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f1bc8-5c39-404a-a5b3-2550680a407d",
   "metadata": {},
   "source": [
    "#### Train without hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b891d91e-eb9b-41cc-b2a4-897638b15a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 10 #size of feature vector\n",
    "C = torch.randn((27, feature_size), requires_grad = True)\n",
    "emb = C[xtr].view(-1, block_size * feature_size)\n",
    "out_size = 27\n",
    "W1 = torch.randn((block_size * feature_size, out_size), requires_grad = True)\n",
    "b1 = torch.randn(out_size, requires_grad = True)\n",
    "\n",
    "parameters = [C, W1, b1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c14fc54c-93e0-486b-b1f1-bf60292a86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without the hidden layer\n",
    "\n",
    "def train(X, Y, num_iters, lr, bs):\n",
    "    # keep stats\n",
    "    lossi = []\n",
    "    iteration = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        ixs = torch.randint(0, X.shape[0], (bs, ))\n",
    "        # forward\n",
    "        logits = torch.tanh((C[X[ixs]].view(-1, block_size * feature_size) @ W1 + b1))\n",
    "        loss = F.cross_entropy(logits, Y[ixs]) + W1.pow(2).mean()\n",
    "    \n",
    "        # backward\n",
    "        for p in parameters: # zero grads\n",
    "            p.grad = None\n",
    "        loss.backward() #backprop\n",
    "\n",
    "        #lr = 0.1 if i < 10000 else lr\n",
    "        if i < 100000:\n",
    "            lr = 0.1\n",
    "        elif ((i > 100000) and (i < 150000)):\n",
    "            lr = 0.01\n",
    "        else:\n",
    "            lr = lr\n",
    "        \n",
    "        for p in parameters: # weight update\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        iteration.append(i)\n",
    "    \n",
    "    return iteration, lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "54db6846-f6d8-4993-9c83-8135eea33c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(x, y):\n",
    "    logits = torch.tanh(C[x].view(-1, block_size * feature_size) @ W1 + b1)\n",
    "    loss = F.cross_entropy(logits, y).item()\n",
    "    print(f'Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0b281622-f83c-4e6f-b0ea-d1efbe39e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, lossi = train(xtr, ytr, 200000, 0.001, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "614b223e-063b-4f95-a98e-ecf4661cd8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5447640419006348\n",
      "Loss: 2.5435798168182373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss(xtr, ytr), eval_loss(xdev, ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78a269-9181-4b8d-a370-d655bf79f5e5",
   "metadata": {},
   "source": [
    "Worse but still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b30aeb00-50d0-4762-b614-7e6085540811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.550022840499878\n"
     ]
    }
   ],
   "source": [
    "eval_loss(xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40094db-9bfa-40b1-81c7-62ccfe4e89a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
